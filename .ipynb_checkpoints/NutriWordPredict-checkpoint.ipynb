{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc3699-d5dd-4601-93f2-ee3bbb8b92f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54aef5c-740c-46d0-9926-85e9ec0b11b1",
   "metadata": {},
   "source": [
    "<h3>Text extraction and Preprocessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c726a22-b36c-48c0-ba3b-20c99b5f2c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_paths):\n",
    "    text = \"\"\n",
    "    for path in pdf_paths:\n",
    "        with open(path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()   \n",
    "    text = re.sub(r'(?<![a-zA-Z0-9])[^a-zA-Z0-9]+(?![a-zA-Z0-9])', '', text)\n",
    "    \n",
    "    # 2. Collapse multiple spaces into one\n",
    "    # text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "#If you want to add more pdf text data, do it here:\n",
    "pdf_paths = [\"text_data/Fundamentals of a healthy and sustainable diet.pdf\", \"text_data/Essentials of Healthy Eating.pdf\", \"text_data/Dietary_Guidelines_for_Americans_2020-2025.pdf\"]\n",
    "raw_text = extract_text_from_pdf(pdf_paths)\n",
    "\n",
    "#get the web scrapped text data here\n",
    "text_file = open(\"webtext.txt\", \"r\")\n",
    "webtext = text_file.read()\n",
    "raw_text += webtext\n",
    "\n",
    "\n",
    "raw_text = clean_text(raw_text)\n",
    "\n",
    "raw_text = raw_text.replace('\\n', '')\n",
    "raw_text = re.split(r'(?<=[.!?]) +', raw_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078ff565-32c6-4631-8217-c38388e571b3",
   "metadata": {},
   "source": [
    "<h3>Tokenize the words</h3>\n",
    "<p>Note: Its worth it to try and write our own tokenizer</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1718d-f727-46b2-8e75-3bf5b9579e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(raw_text)\n",
    "word_counts = tokenizer.word_counts\n",
    "words = 5000#len(tokenizer.word_index) + 1\n",
    "rare_words = [word for word, count in word_counts.items() if count == 1]\n",
    "\n",
    "\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1d90f-c188-47a1-832d-7bd218f0f3df",
   "metadata": {},
   "source": [
    "<h3>Create N-gram sequences and input/output sequences</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c0c53-da20-4b68-92cc-79db14e19fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413726f4-3df0-4c0d-be56-4a734e04db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "inputs = []\n",
    "for line in raw_text:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram = token_list[:i+1]\n",
    "        inputs.append(n_gram)\n",
    "\n",
    "max_sequence_len = 40 #max([len(seq) for seq in inputs])\n",
    "print(max_sequence_len)\n",
    "inputs = np.array(pad_sequences(inputs, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "\n",
    "display(inputs)\n",
    "X = inputs[:, :-1]\n",
    "y = inputs[:, -1]\n",
    "#For cross_entropy uncomment below  \n",
    "#y = np.array(tf.keras.utils.to_categorical(y, num_classes=words))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b33225-4b46-4c8a-920f-90f97d8db724",
   "metadata": {},
   "source": [
    "<h3>Define the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d90ecba5-afe2-482a-9789-b131fa5b83eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">755,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │       \u001b[38;5;34m500,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)           │       \u001b[38;5;34m755,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,405,600</span> (5.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,405,600\u001b[0m (5.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,405,600</span> (5.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,405,600\u001b[0m (5.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(words, 50, input_length=max_sequence_len-1))\n",
    "# model.add(LSTM(150))\n",
    "# model.add(Dense(words, activation='softmax'))\n",
    "# model.build(input_shape=(None, max_sequence_len - 1)) \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(words, 100, input_length=max_sequence_len-1))  # embedding size 100\n",
    "model.add(LSTM(150, return_sequences=False))  # still 1 LSTM, no stacking\n",
    "model.add(Dropout(0.2))  # small dropout to prevent overfitting\n",
    "model.add(Dense(words, activation='softmax'))\n",
    "model.build(input_shape=(None, max_sequence_len-1))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f88ef48-2882-4984-9213-2ae61d1ef73d",
   "metadata": {},
   "source": [
    "<h3>Train the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390f3b9-e4fb-4f5c-895a-253206f0587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2929/2929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 29ms/step - accuracy: 0.0478 - loss: 6.8178 - val_accuracy: 0.1137 - val_loss: 5.9310\n",
      "Epoch 2/50\n",
      "\u001b[1m1550/2929\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 27ms/step - accuracy: 0.1274 - loss: 5.7066"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#split into training sets and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "\n",
    "history = model.fit(\n",
    "  X_train, y_train,\n",
    "  validation_data=(X_val, y_val),\n",
    "  batch_size=32, #you can up this number to 168 will add a boost in training time, but drop in accuracy\n",
    "  epochs=50, # If youre adding more text data, good idea to start w lower number to see how effecieint it is training \n",
    "  callbacks=[EarlyStopping(patience=5, restore_best_weights=True)] #This should stop the training if underfitting is happening\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef7169a-38fd-4765-bbc8-44d08f6556c4",
   "metadata": {},
   "source": [
    "<h3>Plot the metrics</h3>\n",
    "<h>The goal here is to keep the Validatin Accuracy close to the Training accuracy so that model doesnt underfit aka just perform well on the training data and bad on any unknown data</h>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268bba2-95d4-4afd-ba51-e4b2b3fe3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history = model.history\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17365802-257b-4423-a0f8-e10a3d6f98c8",
   "metadata": {},
   "source": [
    "<h3>Save and test the model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23998d-e11c-4a82-8c1e-79063baffddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#NOTE*: to save the model so you dont have to retrain , remember to uncomment here and save it , make sure you change the name\n",
    "# pickle is how you save the tokenizer so that the model can utilize it in future use\n",
    "# Example of how to load it up is in TestingModel.ipynb\n",
    "#*-----------------UNCOMMENT ONCE TRAINING IS DONE---------------*\n",
    "model.save('nutri_model_v1.keras')\n",
    "\n",
    "with open('nutri_tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "seed_text = \"Good Sourcs of Protein include\"\n",
    "\n",
    "print(\"Input Sentence: \" , seed_text)\n",
    "next_words = 20\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "\n",
    "print(\"Next predicted words:\", seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d037f580-f4c4-4101-ba37-59dffe08fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 8 variables whereas the saved optimizer has 14 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model2 = load_model('my_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3fcac2-9227-4d8a-b8e3-60307fc7832a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
